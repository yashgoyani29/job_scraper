# import streamlit as st
# import pandas as pd
# from scraper.freshersworld_scraper import scrape_freshersworld
# from scraper.internshala_scraper import scrape_internshala
# from utils.formatter import save_to_excel, save_to_json

# # ---------------------------------------------------
# st.set_page_config(page_title="Job Aggregation Tool", page_icon="üíº", layout="wide")
# st.title("üíº Job Aggregation Tool")
# st.markdown("Search and aggregate jobs from **Freshersworld** and **Internshala** easily!")

# # ---------------- Dropdown Inputs -------------------
# col1, col2, col3 = st.columns(3)

# with col1:
#     designation = st.selectbox("üéØ Select Designation", [
#         "Python Developer", "Java Developer", "Data Analyst", "Data Scientist",
#         "Web Developer", "Frontend Developer", "Backend Developer",
#         "Full Stack Developer", "Machine Learning Engineer", "Software Engineer",
#         "Business Analyst", "UI/UX Designer", "Android Developer"
#     ])

# with col2:
#     city = st.selectbox("üìç Select City", [
#         "Bangalore", "Hyderabad", "Chennai", "Pune", "Mumbai",
#         "Delhi", "Ahmedabad", "Kolkata", "Noida", "Gurgaon", "Coimbatore", "Jaipur"
#     ])

# with col3:
#     experience = st.selectbox("üéì Experience Level", [
#         "Fresher", "0‚Äì1 Years", "1‚Äì3 Years", "3‚Äì5 Years", "5‚Äì8 Years", "8+ Years"
#     ])

# # ----------------- Scrape Button --------------------
# if st.button("üöÄ Search Jobs"):
#     st.info("‚è≥ Scraping job portals... please wait...")

#     # Dynamic source selection
#     if "fresher" in experience.lower() or "0" in experience:
#         st.write("üßë‚Äçüéì **Detected Fresher Level** ‚Üí Scraping Internshala + Freshersworld")
#         fw_jobs = scrape_freshersworld(designation, city, experience)
#         intern_jobs = scrape_internshala(designation, city, experience)
#         all_jobs = fw_jobs + intern_jobs
#     else:
#         st.write("üë®‚Äçüíº **Experienced Level** ‚Üí Scraping Freshersworld only")
#         all_jobs = scrape_freshersworld(designation, city, experience)

#     # ---------------- Display Results -----------------
#     if all_jobs:
#         df = pd.DataFrame(all_jobs)
#         st.success(f"‚úÖ Found {len(df)} job listings")
#         st.dataframe(df[["Job Title", "Company Name", "Location", "Salary", "Job Portal"]])

#         # Save output
#         save_to_excel(all_jobs, "output/jobs.xlsx")
#         save_to_json(all_jobs, "output/jobs.json")

#         with open("output/jobs.xlsx", "rb") as f:
#             st.download_button(
#                 label="üì• Download Excel File",
#                 data=f,
#                 file_name="jobs.xlsx",
#                 mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#             )

#     else:
#         st.warning("‚ùå No jobs found. Try different filters.")



import streamlit as st
import pandas as pd
from scraper.freshersworld_scraper import scrape_freshersworld
from scraper.internshala_scraper import scrape_internshala
from utils.formatter import save_to_excel, save_to_json

# ---------------------------------------------------
st.set_page_config(page_title="Job Aggregation Tool", page_icon="üíº", layout="wide")
st.title("üíº Job Aggregation Tool")
st.markdown("### üîç Find Jobs & Internships from **Freshersworld** and **Internshala**")

# ---------------- Dropdown Inputs -------------------
col1, col2, col3 = st.columns(3)

with col1:
    designation = st.selectbox("üéØ Select Designation", [
        "Python Developer", "Java Developer", "Data Analyst", "Data Scientist",
        "Web Developer", "Frontend Developer", "Backend Developer",
        "Full Stack Developer", "Machine Learning Engineer", "Software Engineer",
        "Business Analyst", "UI/UX Designer", "Android Developer", "DevOps Engineer",
        "Cloud Engineer", "Digital Marketing Executive", "Automation Tester"
    ])

with col2:
    city = st.selectbox("üìç Select City", [
        "Bangalore", "Hyderabad", "Chennai", "Pune", "Mumbai", "Delhi",
        "Ahmedabad", "Kolkata", "Noida", "Gurgaon", "Coimbatore", "Jaipur",
        "Indore", "Vadodara", "Nagpur", "Surat", "Chandigarh"
    ])

with col3:
    experience = st.selectbox("üéì Experience Level", [
        "Fresher", "0‚Äì1 Years", "1‚Äì3 Years", "3‚Äì5 Years", "5‚Äì8 Years", "8+ Years"
    ])

# ----------------- Scrape Button --------------------
if st.button("üöÄ Search Jobs"):
    st.info("‚è≥ Scraping job portals... Please wait...")

    # üß† Smart Experience Detection
    try:
        if "fresher" in experience.lower() or "0" in experience:
            st.write("üßë‚Äçüéì **Detected Fresher Level** ‚Üí Scraping from Freshersworld + Internshala")
            fw_jobs = scrape_freshersworld(designation, city, experience) or []
            intern_jobs = scrape_internshala(designation, city, experience) or []
            all_jobs = fw_jobs + intern_jobs
        else:
            st.write("üë®‚Äçüíº **Experienced Level** ‚Üí Scraping from Freshersworld only")
            all_jobs = scrape_freshersworld(designation, city, experience) or []
    except Exception as e:
        st.error(f"‚ùå Error during scraping: {str(e)}")
        all_jobs = []

    # ---------------- Combine & Display Results -----------------
    if all_jobs:
        # ‚úÖ Display search criteria prominently
        st.markdown("---")
        st.markdown("### üìã Your Search Criteria")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.markdown(f"**üéØ Job Title:** {designation}")
        with col2:
            st.markdown(f"**üìç Location:** {city}")
        with col3:
            st.markdown(f"**üéì Experience:** {experience}")
        st.markdown("---")
        
        df = pd.DataFrame(all_jobs)

        # ‚úÖ Ensure all columns exist (prevents KeyErrors)
        expected_columns = [
            "Job Title", "Company Name", "Location", "Experience Required",
            "Salary", "Salary / Stipend", "Skills / Role", "Duration",
            "Posted Date", "Job Portal", "Job URL"
        ]
        for col in expected_columns:
            if col not in df.columns:
                df[col] = "N/A"

        # ‚úÖ Merge Salary/Stipend into one unified column
        if "Salary" in df.columns and "Salary / Stipend" in df.columns:
            df["Salary / Stipend"] = df["Salary / Stipend"].where(
                (df["Salary / Stipend"] != "N/A") & (df["Salary / Stipend"] != ""),
                df["Salary"]
            )
            df.drop(columns=["Salary"], inplace=True, errors="ignore")
        elif "Salary" in df.columns:
            df["Salary / Stipend"] = df["Salary"]
            df.drop(columns=["Salary"], inplace=True, errors="ignore")

        # ‚úÖ Remove duplicates (Job Title + Company)
        raw_count = len(df)
        df.drop_duplicates(subset=["Job Title", "Company Name"], inplace=True)
        unique_count = len(df)

        # ‚úÖ Make Job URLs clickable (only for display, keep original for saving)
        df_display = df.copy()
        df_display["Job URL"] = df_display["Job URL"].apply(
            lambda x: f"[üîó View Job]({x})" if isinstance(x, str) and x != "N/A" else "N/A"
        )

        st.info(f"üßæ Merged {raw_count} listings ‚Üí after removing duplicates: **{unique_count} unique jobs saved.**")
        print(f"üßæ Merged {raw_count} listings ‚Üí after removing duplicates: {unique_count} unique jobs saved.")

        # ‚úÖ Show breakdown by portal
        portal_counts = df["Job Portal"].value_counts()
        st.markdown("### üìä Results Breakdown")
        col1, col2, col3 = st.columns(3)
        with col1:
            fw_count = portal_counts.get("Freshersworld", 0)
            st.metric("üè¢ Freshersworld", f"{fw_count} jobs")
        with col2:
            intern_count = portal_counts.get("Internshala", 0)
            st.metric("üéì Internshala", f"{intern_count} internships/jobs")
        with col3:
            st.metric("üìà Total Unique", f"{unique_count} jobs")

        # ‚úÖ Column order for display
        display_cols = [
            "Job Title", "Company Name", "Location", "Experience Required",
            "Salary / Stipend", "Skills / Role", "Duration", "Posted Date",
            "Job Portal"
        ]
        # Ensure display columns exist
        available_display_cols = [col for col in display_cols if col in df_display.columns]

        # ‚úÖ Display results with tabs for better UX
        st.markdown("### üìã Job Listings")
        tab1, tab2, tab3 = st.tabs(["üìä All Jobs", "üéì Internshala Only", "üè¢ Freshersworld Only"])
        
        with tab1:
            st.success(f"‚úÖ Found {len(df)} unique job listings (merged from Freshersworld + Internshala)")
            st.dataframe(df_display[available_display_cols], width='stretch', use_container_width=True, hide_index=True)
            
        with tab3:
            freshersworld_df = df_display[df_display["Job Portal"] == "Freshersworld"]
            if len(freshersworld_df) > 0:
                st.success(f"üè¢ Found {len(freshersworld_df)} jobs from Freshersworld")
                st.dataframe(freshersworld_df[available_display_cols], width='stretch', use_container_width=True, hide_index=True)
            else:
                st.info("‚ÑπÔ∏è No Freshersworld results found.")
        
        with tab2:
            internshala_df = df_display[df_display["Job Portal"] == "Internshala"]
            if len(internshala_df) > 0:
                st.success(f"üéì Found {len(internshala_df)} internships/jobs from Internshala")
                st.markdown("**üí° Tip:** Internshala primarily lists internships and fresher positions.")
                st.dataframe(internshala_df[available_display_cols], width='stretch', use_container_width=True, hide_index=True)
            else:
                st.info("‚ÑπÔ∏è No Internshala results found. Try searching for fresher positions (0-1 years experience).")

        # ‚úÖ Save outputs (save full dataframe with ALL columns - no filtering)
        # Get all columns from dataframe (excluding any searched job title if it exists)
        all_columns = [col for col in df.columns if col != "Searched Job Title"]
        all_jobs_data = df[all_columns].to_dict(orient="records")
        
        # Save complete job data with all fields (without searched job title)
        save_to_excel(all_jobs_data, "output/jobs.xlsx")
        save_to_json(all_jobs_data, "output/jobs.json")
        st.info(f"üíæ Saved {len(all_jobs_data)} complete job records (all fields included) to JSON and Excel files")

        # ‚úÖ Download Buttons
        colA, colB = st.columns(2)
        with colA:
            with open("output/jobs.xlsx", "rb") as f:
                st.download_button(
                    label="üì• Download Excel File",
                    data=f,
                    file_name="jobs.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

        with colB:
            with open("output/jobs.json", "rb") as f:
                st.download_button(
                    label="üìÑ Download JSON File",
                    data=f,
                    file_name="jobs.json",
                    mime="application/json"
                )

    else:
        st.warning("‚ùå No jobs found. Try changing your filters.")
